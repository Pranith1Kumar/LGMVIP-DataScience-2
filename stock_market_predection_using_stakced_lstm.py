# -*- coding: utf-8 -*-
"""Stock Market Predection using Stakced LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V0z0VtwJ91PGVpf9mkZApX5eBxMsJXg1

Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler

target=pd.read_csv('NSE-TATAGLOBAL.csv')
target.head()
target.tail()

target.describe()

"""Sorting the data"""

sort=[(c,target[c].isnull().mean()*100) for c in target]
sort=pd.DataFrame(sort,columns=['column_name','percentage'])
sort

srt=target.sort_values(by='Date')
srt.head()

srt.reset_index(inplace=True)
srt.head()

"""Data Visualization"""

plt.figure(figsize=(10,7))
plt.plot(srt['Date'],srt['Close'])

close_srt=srt['Close']
print(close_srt)

"""Scaling"""

scaler=MinMaxScaler(feature_range=(0,1))
close_srt=scaler.fit_transform(np.array(close_srt).reshape(-1,1))
print(close_srt)

"""Splitting"""

train_size=int(len(close_srt)*0.7)
test_size=len(close_srt)-train_size
train_data,test_data=close_srt[0:train_size,:],close_srt[train_size:len(close_srt),:1]

#training
train_data.shape

#testing
test_data.shape

def create_dataset(dataset,time_step=1):
  datax,datay=[],[]
  for i in range(len(dataset)-time_step-1):
    a=dataset[i:(i+time_step),0]
    datax.append(a)
    datay.append(dataset[i+time_step,0])
  return np.array(datax),np.array(datay)

"""Reshaping dataset"""

time_step=100
x_train,y_train=create_dataset(train_data,time_step)
x_test,y_test=create_dataset(test_data,time_step)

#training the dataset
print(x_train.shape),print(y_train.shape)

#testing the dataset
print(x_test.shape),print(y_test.shape)

x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)
x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)

#train
x_train

#test
x_test

"""Creation of LSTM"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM

model=Sequential()
model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))
model.add(LSTM(50,return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))
model.compile(loss='mean_squared_error',optimizer='adam')

#summary print of above
model.summary()

from re import VERBOSE
model.fit(x_train,y_train,validation_split=0.1,epochs=60,batch_size=64,verbose=1)

train_predict=model.predict(x_train)
test_predict=model.predict(x_test)

train_predict=scaler.inverse_transform(train_predict)
test_predict=scaler.inverse_transform(test_predict)

#caluculating performance
import math
from sklearn.metrics import mean_squared_error
#train
math.sqrt(mean_squared_error(y_train,train_predict))
#test
math.sqrt(mean_squared_error(y_test,test_predict))

look_back=100
trainPredictPlot=np.empty_like(close_srt)
trainPredictPlot[:,:]=np.nan
trainPredict[look_back:len(train_predict)+look_back,:]=train_predict

#shift test predictions
testPredictPlot=np.empty_like(close_srt)
testPredictPlot[:,:]=np.nan
testPredictPlot[len(train_predict)+(look_back*2)+1:len(close_srt)-1,:]=test_predict

plt.figure(figsize=(10,7))
plt.plot(scaler.inverse_transform(close_srt))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

"""Prediction for next 30 days"""

len(test_data)

pred_input=test_data[511:].reshape(1,-1)
pred_input.shape

temp_input=list(pred_input)
temp_input=temp_input[0].tolist()
temp_input

day_new=np.arange(1,101)
day_pred=np.arange(101,131)
len(close_srt)

plt.figure(figsize=(10,7))
plt.plot(day_new,scaler.inverse_transform(close_srt[1935:]))

df3=close_srt.tolist()
len(df3)

plt.figure(figsize=(10,7))
plt.plot(df3[1935:])

df2=scaler.inverse_transform(df3).tolist()

plt.figure(figsize=(10,7))
plt.plot(df2)